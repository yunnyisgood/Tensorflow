import numpy as np
import matplotlib.pyplot as plt

'''
초기값 변경
lr 변경
MaxIter 변경에 따라 언제 수렴하는지 

'''

f = lambda x: x**2 -4*x +6 # y값 구하는 함수

gradient = lambda x:2*x - 4 


x0 = 0.0 # 초기값
MaxIter = 20
learning_rate = 0.25 # 오른쪽으로 0.25만큼 움직인다

print("step\txo\tf(x)")
print("{:02d}\t{:6.5f}\t{:6.5f}".format(0, x0, f(x0)))

for i in range(MaxIter):
    # 초기값 x0을 갱신한다 
    x1 = x0 - learning_rate * gradient(x0) # 초기위치 - (기울기 x 학습률)
    # 경사하강법 알고리즘: 기울기에 학습률을 곱해 다음 지정을 결정 
    x0 = x1

    print("{:02d}\t{:6.5f}\t{:6.5f}".format(i+1, x0, f(x0)))


'''
lr이 커질 수록 MaxIter 값도 커져야 언제 수렴되는지 파악 가능


step    s       f(x)
00      0.00000 6.00000
01      1.00000 3.00000
02      1.50000 2.25000
03      1.75000 2.06250
04      1.87500 2.01562
05      1.93750 2.00391
06      1.96875 2.00098
07      1.98438 2.00024
08      1.99219 2.00006
09      1.99609 2.00002
10      1.99805 2.00000 >> 여기서부터 2에 수렴된다 
11      1.99902 2.00000
12      1.99951 2.00000
13      1.99976 2.00000
14      1.99988 2.00000
15      1.99994 2.00000
16      1.99997 2.00000
17      1.99998 2.00000
18      1.99999 2.00000
19      2.00000 2.00000
20      2.00000 2.00000

=> 아느 시점에서 x와 y모두 2에 수렴한다 

'''